{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehmetalianil/epoch-15/blob/master/First%20Day.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fpMCI8yA47p",
        "colab_type": "text"
      },
      "source": [
        "# First day\n",
        "\n",
        "This day, we are going to do the following: \n",
        "* If not done yet, we need to sort out some prerequisites.\n",
        "* We are going to generate a dataset of hand gestures, together.\n",
        "* We might spend some time to gather and preprocess the data. (Never underestimate time spent for data-prep)\n",
        "* Then we will start a Tensorflow session, and try to solve a classification problem of classifying these gestures correctly.\n",
        "\n",
        "## Resources\n",
        "* Arduino IDE download link https://www.arduino.cc/en/Main/Software\n",
        "* Linux CH340 drivers patching guide https://learn.sparkfun.com/tutorials/how-to-install-ch340-drivers/all#linux\n",
        "* Upload point for generated data: https://drive.google.com/drive/folders/138hSEWZyePWepjaOIrhxuYEvBwqLl2PM?usp=sharing\n",
        "\n",
        "## Introduction\n",
        "\n",
        "*There might be new faces in this session, therefore I would like to write an introduction.*\n",
        "\n",
        "I am Mehmet Ali Anil, co-founder of Grus in High Tech Campus. I am a electrical engineer and physicist with particular interest on biologically inspired systems for a while now. Here are the places that you can contact me and read things I write: \n",
        "\n",
        "* Github https://github.com/mehmetalianil\n",
        "* StackOverflow https://stackexchange.com/users/462542/mehmet-ali-anil\n",
        "* LinkedIn https://www.linkedin.com/in/mehmetalianil/\n",
        "* Our blog https://blog.grusbv.com/\n",
        "* Twitter https://twitter.com/maanil_ee \n",
        "* Podcast {{Work In Progress}}\n",
        "\n",
        "## Why microcontrollers? Isn't ML the job for, like endless server farms?\n",
        "It doesn't have to be. It might have been a bad idea before, but the unexpected success of deep learning on specific problems has laid the groundwork for its widespread applicability. And systems with small resources, given a small problem to solve excel in applications that require: \n",
        "\n",
        "* Autonomy\n",
        "* Privacy\n",
        "* Speed (as in latency)\n",
        "* Energy efficiency\n",
        "\n",
        "In short, life is what is here and now, and why not solve problems where they are?\n",
        "\n",
        "There are many ways to incorporate machine learning in embedded devices, but I am personally intrigued by the idea of using microcontrollers that are essentially ubiquotus now. [This Quora link](https://www.quora.com/How-many-embedded-systems-are-there) states that there might be 75-100 billions of devices housing microcontrollers. Due to their nature, these microcontrollers are used for tasks that involve deterministic control. They are so cheap and widespread that they might just as well be hardware neurons in our designs. We just need to learn how to program them. That is what we are up to. \n",
        "\n",
        "## We have some prerequisites.\n",
        "\n",
        "### Get a serial monitor\n",
        "\n",
        "We need a serial terminal to get our data out of our sparkfun boards. There are a few candidates:\n",
        "\n",
        "* Docklight\n",
        "* Tera Term\n",
        "* screen (Linux terminal)\n",
        "* Arduino IDE (I tested it here)\n",
        "\n",
        " I have chosen Arduino because it also has a plotter that graphs the serial data stream if it has comma separated values. \n",
        "\n",
        "### If using Linux, download patched CH340 drivers\n",
        "The current driver in the Linux kernel needs to be patched before programming the device with high speeds around 1MHz. It might be okay today, since we will only program if we have the time, but keep it in mind, follow the guidelines here:\n",
        "\n",
        "https://learn.sparkfun.com/tutorials/how-to-install-ch340-drivers/all#linux\n",
        "\n",
        "## Lets generate data\n",
        "\n",
        "* Plug the USB cable to the computer.\n",
        "* Plug the serial converter board on, the dark board.\n",
        "* Plug the red Sparkfun Edge board on the serial converter board. They should both be chip side up. (The sparkfun board has a GRN written on the top pin,  which is **not** and indication that it must be connected to GND on the serial converter.)\n",
        "* Your board might have some of its lights on, don't worry. \n",
        "* Fire up Arduino IDE, `Ctrl`+`Shift`+`L` or `Tools>>Serial Plotter` to fire up the serial plotter. \n",
        "* Press the button on your board marked as RST while watching the Serial Plotter. Sparkfun edge board will send a record of 2 seconds woorth of accelerometer readings.\n",
        "* Experiment with the accelerometer if you are into that sort of things. Check whether gravity is still 1G. \n",
        "* Hold the boards secure in your hand (you can hold by the serial board) and come up with a hand gesture that you can do within a second, something bold and makes a distinct waveform on the serial plotter. Start and stop without jerking the device. Practice here. (Each person, one gesture.)\n",
        "* Name this gesture, draw it up on the board to avoid different people choosing very similar gestures.\n",
        "* Close the serial plotter, fire up the serial monitor with `Ctrl`+`Shift`+`M` or `Tools>>Serial Monitor`\n",
        "* Now, record as many gestures as you can. Press the RST button on the device, and execute the gesture. Try to get the gesture into the middle of the 2 minute window. Try to have a single way of holding the boards, start and stop without motion. \n",
        "* If there are some spurious signal, it is due to the cable and the connections. check them out and continue. I will clean them out by hand.\n",
        "* After sone, copy paste the output into a file named for your gesture, with the extension .csv. It should be like: \"fistbump.csv\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItqYkJ0AAdG3",
        "colab_type": "code",
        "outputId": "27cc98d5-26ee-4055-c552-8618b0e13eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Run this command in order to download or update the dataset that we are building up from scratch!\n",
        "!gsutil -m cp -r gs://epoch-15 ./"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://epoch-15/zorro.csv...\n",
            "/ [1/1 files][610.9 KiB/610.9 KiB] 100% Done                                    \n",
            "Operation completed over 1 objects/610.9 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}